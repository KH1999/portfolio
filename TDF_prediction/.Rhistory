adaModel_opt <- xgb.train(data = dtrain,
nrounds = 20,
eta=0.1,
objective = "binary:logistic",
verbose = 2,
watchlist = watchlist,
eval_metric = 'auc')
history <- adaModel_opt$evaluation_log
history %>% pivot_longer(2:3,names_to = "set", values_to = "performance") %>%
ggplot(., aes(iter, performance, col = set))+
geom_point() + geom_line() +
facet_wrap(~set, )
set.seed(123)
opt_iter <- history$iter[which.max(history$test_auc)]
adaModel_opt <- xgb.train(data = dtrain,
nrounds = opt_iter,
eta=0.1,
objective = "binary:logistic",
verbose = 2,
eval_metric = 'auc')
set.seed(123)
ABmodel <- ada(y_train ~ . ,train_fs,iter=opt_iter)
predAB <- as.numeric(predict(ABmodel,val_fs,type="probs")[,2])
AUC::auc(roc(predAB,y_val))
predAB <- as.numeric(predict(ABmodel,test_fs,type="probs")[,2])
auc_ada <-AUC::auc(roc(predAB,y_test))
res <-ifelse(predAB>=0.5,1,0)
true_outcome <- y_test
confusionMatrix(as.factor(res), as.factor(true_outcome))[[2]]
TN =(confusionMatrix(as.factor(res), as.factor(true_outcome)))[[2]][1,1]
TP = (confusionMatrix(as.factor(res), as.factor(true_outcome)))[[2]][2,2]
FN = (confusionMatrix(as.factor(res), as.factor(true_outcome)))[[2]][1,2]
FP = (confusionMatrix(as.factor(res), as.factor(true_outcome)))[[2]][2,1]
accuracy = (TP+TN)/(TP+FP+TN+FN)
recall = TP/(TP+FN)
precision = TP/(TP+FP)
paste("AUC: ", auc)
paste("Accuracy: ", accuracy)
paste("Recall: ", recall)
paste("Precision: ", precision)
table_train5 <- table_train
table_val5 <- table_val
table_test5 <- table_test
table_train5$Top10 <- NULL
table_train5$Top4 <- NULL
table_train5$Top3 <- NULL
table_train5$Top2 <- NULL
table_val5$Top10 <- NULL
table_val5$Top4 <- NULL
table_val5$Top3 <- NULL
table_val5$Top2 <- NULL
table_test5$Top10 <- NULL
table_test5$Top4 <- NULL
table_test5$Top3 <- NULL
table_test5$Top2 <- NULL
#Variable selection: Boruta
rf_boruta <- Boruta(table_train5[, !names(table_train5) %in% c("Top5"
)], table_train5$Top5, doTrace = 0)
varsel_boruta <- names(rf_boruta$finalDecision[rf_boruta$finalDecision ==
"Confirmed"])
#new train en val set
y_train <- table_train5$Top5
train <- table_train5
train$Top5<- NULL
y_val <- table_val5$Top5
val <- table_val5
val$Top5 <-NULL
y_test <- table_test5$Top5
test <- table_test
table_test5$Top5 <- NULL
train_fs <- train[varsel_boruta]
val_fs <- val[varsel_boruta]
test_fs <- test[varsel_boruta]
p_load(lightgbm)
leaves <- c(2, 4, 6, 8)
nround <- c(2, 5, 10, 20, 50, 100, 200)
learning_rate <- c(0.01, 0.05, 0.1, 0.2, 0.5)
# create data frame of all possible combinations
params <- expand.grid(leaves, nround, learning_rate)
colnames(params) <- c("leaves", "nround", "learning_rate")
aucs <- vector()
set.seed(123)
for (row in 1:nrow(params)) {
# set parameters
par <- params[row, ]
param_set <- list(num_leaves = par[, "leaves"], learning_rate = par[,
"learning_rate"], objective = "binary", boosting = "gbdt",
num_iterations = par[, "nround"])
# model
lgbm_model <- lightgbm(data = as.matrix(train_fs),
params = param_set, label = as.numeric(as.character(y_train)),
verbose = -1)
# predict
pred <- predict(lgbm_model, as.matrix(val_fs))
# evaluate
aucs[row] <- AUC::auc(AUC::roc(pred, y_val))
}
(optimal_paramsLGBM <- params[which.max(aucs), ])
# Build the final model on the optimal parameters
final_param_set <- list(num_leaves = optimal_paramsLGBM[, "leaves"],
learning_rate = optimal_paramsLGBM[, "learning_rate"], objective = "binary",
boosting = "gbdt", num_iterations = optimal_paramsLGBM[,
"nround"])
lgbm_model <- lightgbm(data = as.matrix(train_fs), params = final_param_set,
label = as.numeric(as.character(y_train)), verbose = -1)
# Predict
predlgbm <- predict(lgbm_model, as.matrix(val_fs))
# Evaluate
AUC::auc(AUC::roc(predlgbm, y_val))
predlgbm <- predict(lgbm_model, as.matrix(test_fs))
auc <-AUC::auc(AUC::roc(predlgbm, y_test))
res <-ifelse(predlgbm>=0.5,1,0)
true_outcome <- y_test
confusionMatrix(as.factor(res), as.factor(true_outcome))[[2]]
TN =(confusionMatrix(as.factor(res), as.factor(true_outcome)))[[2]][1,1]
TP = (confusionMatrix(as.factor(res), as.factor(true_outcome)))[[2]][2,2]
FN = (confusionMatrix(as.factor(res), as.factor(true_outcome)))[[2]][1,2]
FP = (confusionMatrix(as.factor(res), as.factor(true_outcome)))[[2]][2,1]
accuracy = (TP+TN)/(TP+FP+TN+FN)
recall = TP/(TP+FN)
precision = TP/(TP+FP)
paste("Accuracy: ", accuracy)
paste("Recall: ", recall)
paste("Precision: ", precision)
## Rotation forest
set.seed(123)
vector <- seq(10, 200, by=10)
AUC_stored <- vector()
# adaboost & rotation
finalpredictions <- (auc_RoF/(auc_RoF + auc_ada)) * pred_RoF_test + (auc_ada/(auc_RoF + auc_ada)) * predAB
set.seed(123)
ABmodel <- ada(y_train ~ . ,train_fs,iter=opt_iter)
predAB <- as.numeric(predict(ABmodel,val_fs,type="probs")[,2])
AUC::auc(roc(predAB,y_val))
predAB <- as.numeric(predict(ABmodel,test_fs,type="probs")[,2])
auc_ada <-AUC::auc(roc(predAB,y_test))
# adaboost & rotation
finalpredictions <- (auc_RoF/(auc_RoF + auc_ada)) * pred_RoF_test + (auc_ada/(auc_RoF + auc_ada)) * predAB
AUC::auc(AUC::roc(finalpredictions, basetable_test$Top5))
# accuracy
res <-ifelse(finalpredictions>=0.5,1,0)
true_outcome <- basetable_test$Top5
confusionMatrix(as.factor(res), as.factor(true_outcome))[[2]]
library(pacman)
p_load(lubridate, AUC, tidyverse,magrittr, dplyr, tidyr,rlist,dummy , e1071, ROSE , rotationForest, xgboost, Boruta, varSelRF, caret)
p_load(caret)
p_load(FNN)
p_load(randomForest)
options(repr.matrix.max.cols=1000, repr.matrix.max.rows=1000)
p_load(ranger)
table = (read.csv("Data//Hilly_races_final.csv", sep = ";"))
head(table)
table_train = table[table$Year<=2017,]
table_val = table[(table$Year>2017)&(table$Year<=2019) ,]
table_test = table[table$Year>2019,]
table_train2 = table[table$Year<=2019,]
basetable_train = table_train %>% group_by(Race, Year,Team) %>% summarise(flat_mean = round(mean(FLAT))
, mountain_mean = round(mean(MOUNTAIN))
, downhill_mean = round(mean(DOWNHILL))
,cobbles_mean = round(mean(COBBLES))
,tt_mean = round(mean(TT)),
,prologue_mean = round(mean(PROLOGUE))
,sprint_mean = round(mean(SPRINT))
,acceleration_mean = round(mean(ACCELERATION))
,endurance_mean = round(mean(ENDURANCE))
,resistance_mean = round(mean(RESISTANCE))
,recup_mean = round(mean(RECUP))
,hill_mean = round(mean(HILL))
,attack_mean = round(mean(ATTACK))
,flat_max = round(max(FLAT))
,mountain_max = round(max(MOUNTAIN))
,downhill_max = round(max(DOWNHILL))
,cobbles_max = round(max(COBBLES))
,tt_max = round(max(TT)),
,prologue_max = round(max(PROLOGUE))
,sprint_max = round(max(SPRINT))
,acceleration_max = round(max(ACCELERATION))
,endurance_max = round(max(ENDURANCE))
,resistance_max = round(max(RESISTANCE))
,recup_max = round(max(RECUP))
,hill_max = round(max(HILL))
,attack_max = round(max(ATTACK))
,flat_min = round(min(FLAT))
,mountain_min = round(min(MOUNTAIN))
,downhill_min = round(min(DOWNHILL))
,cobbles_min = round(min(COBBLES))
,tt_min = round(min(TT)),
,prologue_min = round(min(PROLOGUE))
,sprint_min = round(min(SPRINT))
,acceleration_min = round(min(ACCELERATION))
,endurance_min = round(min(ENDURANCE))
,resistance_min = round(min(RESISTANCE))
,recup_min = round(min(RECUP))
,hill_min = round(min(HILL))
,attack_min = round(min(ATTACK))
,best_position = min(Pos))
basetable_val = table_val %>% group_by(Race, Year,Team) %>% summarise(flat_mean = round(mean(FLAT))
, mountain_mean = round(mean(MOUNTAIN))
, downhill_mean = round(mean(DOWNHILL))
,cobbles_mean = round(mean(COBBLES))
,tt_mean = round(mean(TT)),
,prologue_mean = round(mean(PROLOGUE))
,sprint_mean = round(mean(SPRINT))
,acceleration_mean = round(mean(ACCELERATION))
,endurance_mean = round(mean(ENDURANCE))
,resistance_mean = round(mean(RESISTANCE))
,recup_mean = round(mean(RECUP))
,hill_mean = round(mean(HILL))
,attack_mean = round(mean(ATTACK))
,flat_max = round(max(FLAT))
,mountain_max = round(max(MOUNTAIN))
,downhill_max = round(max(DOWNHILL))
,cobbles_max = round(max(COBBLES))
,tt_max = round(max(TT)),
,prologue_max = round(max(PROLOGUE))
,sprint_max = round(max(SPRINT))
,acceleration_max = round(max(ACCELERATION))
,endurance_max = round(max(ENDURANCE))
,resistance_max = round(max(RESISTANCE))
,recup_max = round(max(RECUP))
,hill_max = round(max(HILL))
,attack_max = round(max(ATTACK))
,flat_min = round(min(FLAT))
,mountain_min = round(min(MOUNTAIN))
,downhill_min = round(min(DOWNHILL))
,cobbles_min = round(min(COBBLES))
,tt_min = round(min(TT)),
,prologue_min = round(min(PROLOGUE))
,sprint_min = round(min(SPRINT))
,acceleration_min = round(min(ACCELERATION))
,endurance_min = round(min(ENDURANCE))
,resistance_min = round(min(RESISTANCE))
,recup_min = round(min(RECUP))
,hill_min = round(min(HILL))
,attack_min = round(min(ATTACK))
,best_position = min(Pos))
basetable_test = table_test %>% group_by(Race, Year,Team) %>% summarise(flat_mean = round(mean(FLAT))
, mountain_mean = round(mean(MOUNTAIN))
, downhill_mean = round(mean(DOWNHILL))
,cobbles_mean = round(mean(COBBLES))
,tt_mean = round(mean(TT)),
,prologue_mean = round(mean(PROLOGUE))
,sprint_mean = round(mean(SPRINT))
,acceleration_mean = round(mean(ACCELERATION))
,endurance_mean = round(mean(ENDURANCE))
,resistance_mean = round(mean(RESISTANCE))
,recup_mean = round(mean(RECUP))
,hill_mean = round(mean(HILL))
,attack_mean = round(mean(ATTACK))
,flat_max = round(max(FLAT))
,mountain_max = round(max(MOUNTAIN))
,downhill_max = round(max(DOWNHILL))
,cobbles_max = round(max(COBBLES))
,tt_max = round(max(TT)),
,prologue_max = round(max(PROLOGUE))
,sprint_max = round(max(SPRINT))
,acceleration_max = round(max(ACCELERATION))
,endurance_max = round(max(ENDURANCE))
,resistance_max = round(max(RESISTANCE))
,recup_max = round(max(RECUP))
,hill_max = round(max(HILL))
,attack_max = round(max(ATTACK))
,flat_min = round(min(FLAT))
,mountain_min = round(min(MOUNTAIN))
,downhill_min = round(min(DOWNHILL))
,cobbles_min = round(min(COBBLES))
,tt_min = round(min(TT)),
,prologue_min = round(min(PROLOGUE))
,sprint_min = round(min(SPRINT))
,acceleration_min = round(min(ACCELERATION))
,endurance_min = round(min(ENDURANCE))
,resistance_min = round(min(RESISTANCE))
,recup_min = round(min(RECUP))
,hill_min = round(min(HILL))
,attack_min = round(min(ATTACK))
,best_position = min(Pos))
basetable = table_train2 %>% group_by(Race, Year,Team) %>% summarise(flat_mean = round(mean(FLAT))
, mountain_mean = round(mean(MOUNTAIN))
, downhill_mean = round(mean(DOWNHILL))
,cobbles_mean = round(mean(COBBLES))
,tt_mean = round(mean(TT)),
,prologue_mean = round(mean(PROLOGUE))
,sprint_mean = round(mean(SPRINT))
,acceleration_mean = round(mean(ACCELERATION))
,endurance_mean = round(mean(ENDURANCE))
,resistance_mean = round(mean(RESISTANCE))
,recup_mean = round(mean(RECUP))
,hill_mean = round(mean(HILL))
,attack_mean = round(mean(ATTACK))
,flat_max = round(max(FLAT))
,mountain_max = round(max(MOUNTAIN))
,downhill_max = round(max(DOWNHILL))
,cobbles_max = round(max(COBBLES))
,tt_max = round(max(TT)),
,prologue_max = round(max(PROLOGUE))
,sprint_max = round(max(SPRINT))
,acceleration_max = round(max(ACCELERATION))
,endurance_max = round(max(ENDURANCE))
,resistance_max = round(max(RESISTANCE))
,recup_max = round(max(RECUP))
,hill_max = round(max(HILL))
,attack_max = round(max(ATTACK))
,flat_min = round(min(FLAT))
,mountain_min = round(min(MOUNTAIN))
,downhill_min = round(min(DOWNHILL))
,cobbles_min = round(min(COBBLES))
,tt_min = round(min(TT)),
,prologue_min = round(min(PROLOGUE))
,sprint_min = round(min(SPRINT))
,acceleration_min = round(min(ACCELERATION))
,endurance_min = round(min(ENDURANCE))
,resistance_min = round(min(RESISTANCE))
,recup_min = round(min(RECUP))
,hill_min = round(min(HILL))
,attack_min = round(min(ATTACK))
,best_position = min(Pos))
basetable_train = (basetable_train)%>% drop_na()
basetable_val = (basetable_val)%>% drop_na()
basetable_test = (basetable_test)%>% drop_na()
basetable = (basetable)%>% drop_na()
basetable_train$Top10 = as.factor(ifelse(basetable_train$best_position <=10, 1,0))
basetable_train$Top5 = as.factor(ifelse(basetable_train$best_position <=5, 1,0))
basetable_train$Top4 = as.factor(ifelse(basetable_train$best_position <=4, 1,0))
basetable_train$Top3 = as.factor(ifelse(basetable_train$best_position <=3, 1,0))
basetable_train$Top2 = as.factor(ifelse(basetable_train$best_position <=2, 1,0))
table(basetable_train$Top10)
basetable_train$minutes_from_top = NULL
basetable_train$best_position = NULL
basetable_train$Team = NULL
basetable_train$Year = NULL
basetable_train$Stage = NULL
basetable_train$Team_ID = NULL
basetable_train$Race= NULL
basetable_val$Top10 = as.factor(ifelse(basetable_val$best_position <=10, 1,0))
basetable_val$Top5 = as.factor(ifelse(basetable_val$best_position <=5, 1,0))
basetable_val$Top4 = as.factor(ifelse(basetable_val$best_position <=4, 1,0))
basetable_val$Top3 = as.factor(ifelse(basetable_val$best_position <=3, 1,0))
basetable_val$Top2 = as.factor(ifelse(basetable_val$best_position <=2, 1,0))
table(basetable_val$Top10)
basetable_val$minutes_from_top = NULL
basetable_val$best_position = NULL
basetable_val$Team = NULL
basetable_val$Year = NULL
basetable_val$Stage = NULL
basetable_val$Team_ID = NULL
basetable_val$Race= NULL
basetable_test$Top10 = as.factor(ifelse(basetable_test$best_position <=10, 1,0))
basetable_test$Top5 = as.factor(ifelse(basetable_test$best_position <=5, 1,0))
basetable_test$Top4 = as.factor(ifelse(basetable_test$best_position <=4, 1,0))
basetable_test$Top3 = as.factor(ifelse(basetable_test$best_position <=3, 1,0))
basetable_test$Top2 = as.factor(ifelse(basetable_test$best_position <=2, 1,0))
table(basetable_test$Top5)
basetable_test$minutes_from_top = NULL
basetable_test$best_position = NULL
basetable_test$Team = NULL
basetable_test$Year = NULL
basetable_test$Stage = NULL
basetable_test$Team_ID = NULL
basetable_test$Race= NULL
basetable$Top10 = as.factor(ifelse(basetable$best_position <=10, 1,0))
basetable$Top5 = as.factor(ifelse(basetable$best_position <=5, 1,0))
basetable$Top4 = as.factor(ifelse(basetable$best_position <=4, 1,0))
basetable$Top3 = as.factor(ifelse(basetable$best_position <=3, 1,0))
basetable$Top2 = as.factor(ifelse(basetable$best_position <=2, 1,0))
table(basetable$Top5)
basetable$minutes_from_top = NULL
basetable$best_position = NULL
basetable$Team = NULL
basetable$Year = NULL
basetable$Stage = NULL
basetable$Team_ID = NULL
basetable$Race= NULL
table_train <- basetable_train
table_test<- basetable_test
table_val <- basetable_val
table_trainBIG <- basetable
# hyperparameter grid search
hyper_grid <- expand.grid(
num_trees = c(1000),
mtry       = seq(15, 35, by = 1),
node_size  = seq(1, 13, by = 2),
sampe_size = c(.55, .632, .70,0.75,.80),
OOB_RMSE   = 0
)
nrow(hyper_grid)
set.seed(123)
for(i in 1:nrow(hyper_grid)) {
# train model
model <- ranger(
x               = basetable_train[,-(40:43)],
y               = basetable_train$Top5,
num.trees       = hyper_grid$mtry[i],
mtry            = hyper_grid$mtry[i],
min.node.size   = hyper_grid$node_size[i],
sample.fraction = hyper_grid$sampe_size[i],
probability     = TRUE,
seed            = 123
)
# add OOB error to grid
hyper_grid$OOB_RMSE[i] <- sqrt(model$prediction.error)
}
hyper_grid %>%
dplyr::arrange(OOB_RMSE) %>%
head(10)
# By setting a new unique seed, you ensure a different
# 'random' split
seeds <- c(123, 246, 91, 949, 9000, 1860, 1853, 1416, 515, 369,145,36920,877,124,617,1743,4852,9001,9005,9004,14,15,19,18,246,47,1,2,3,4,5,6,7,20)  #give 10 random values
all_aucs <- vector(length = length(seeds))
set.seed(123)
for (i in 1:length(seeds)) {
set.seed(seeds[i])
allind <- sample(x = 1:nrow(basetable_train), size = nrow(basetable_train),
replace = TRUE)  # WITH replacement
# block to get indices
trainind <- allind[1:round(length(allind) * 0.70)]
testind <- allind[!allind %in% trainind]  #get all indices which are not in training
#actual subsetting
train <- basetable_train[trainind, ]
yTRAIN <- train$Top5
train$Top10 = NULL
train$Top5 = NULL
train$Top4 = NULL
train$Top3 = NULL
train$Top2 = NULL
test <- basetable_train[testind, ]
yTEST <- test$Top5
test$Top5 <- NULL
test$Top5 = NULL
test$Top4 = NULL
test$Top3 = NULL
test$Top2 = NULL
#fit
model <- ranger(x=train, y = yTRAIN, num.trees = 500, mtry = 10, sample.fraction = 0.75, probability = TRUE)
# predict on second set (test)0
predictions =  predict(model,test)$predictions[,2]
# evaluate and store
all_aucs[i] <- AUC::auc(roc(predictions, yTEST))
}
# Plot
plot(all_aucs, type = "b")
mean(all_aucs)
set.seed(123)
train <- basetable_train
yTRAIN <- train$Top5
train$Top10 = NULL
train$Top5 = NULL
train$Top4 = NULL
train$Top3 = NULL
train$Top2 = NULL
test <- basetable_val
yTEST <- test$Top5
test$Top10 = NULL
test$Top5 = NULL
test$Top4 = NULL
test$Top3 = NULL
test$Top2 = NULL
set.seed(123)
#fit
rFmodel <- randomForest(x=train, y = yTRAIN, ntree = 1000,mtry=15)
# predict on second set (test)
predictions <- predict(rFmodel, test, type = "prob")[, 2]
AUC::auc(roc(predictions,factor(yTEST)))
auc = AUC::auc(roc(predictions,factor(yTEST)))
res = ifelse(predictions>=0.5,1,0)
true_outcome = yTEST
confusionMatrix(as.factor(res), as.factor(true_outcome))[[2]]
TN =(confusionMatrix(as.factor(res), as.factor(true_outcome)))[[2]][1,1]
TP = (confusionMatrix(as.factor(res), as.factor(true_outcome)))[[2]][2,2]
FN = (confusionMatrix(as.factor(res), as.factor(true_outcome)))[[2]][1,2]
FP = (confusionMatrix(as.factor(res), as.factor(true_outcome)))[[2]][2,1]
accuracy = (TP+TN)/(TP+FP+TN+FN)
recall = TP/(TP+FN)
precision = TP/(TP+FP)
paste("AUC: ", auc)
paste("Accuracy: ", accuracy)
paste("Recall: ", recall)
paste("Precision: ", precision)
#fit on training set
model <- ranger(x=train, y = yTRAIN, num.trees = 1000, mtry = 8,min.node.size = 13, sample.fraction = 0.75, probability = TRUE, seed = 123)
# predict on validation set
predictions =  predict(model,test)$predictions[,2]
AUC::auc(roc(predictions,factor(yTEST)))
auc = AUC::auc(roc(predictions,factor(yTEST)))
res = ifelse(predictions>=0.5,1,0)
true_outcome = yTEST
confusionMatrix(as.factor(res), as.factor(true_outcome))[[2]]
TN =(confusionMatrix(as.factor(res), as.factor(true_outcome)))[[2]][1,1]
TP = (confusionMatrix(as.factor(res), as.factor(true_outcome)))[[2]][2,2]
FN = (confusionMatrix(as.factor(res), as.factor(true_outcome)))[[2]][1,2]
FP = (confusionMatrix(as.factor(res), as.factor(true_outcome)))[[2]][2,1]
accuracy = (TP+TN)/(TP+FP+TN+FN)
recall = TP/(TP+FN)
precision = TP/(TP+FP)
paste("AUC: ", auc)
paste("Accuracy: ", accuracy)
paste("Recall: ", recall)
paste("Precision: ", precision)
#TEST
test <- basetable_test
yTEST <- test$Top5
test$Top10 = NULL
test$Top5 = NULL
test$Top4 = NULL
test$Top3 = NULL
test$Top2 = NULL
# predict on second set (test)
predictions =  predict(model,test)$predictions[,2]
set.seed(123)
#fit
rFmodel <- randomForest(x=basetable, y = basetable$Top5, ntree = 1000,mtry=15)
# predict on second set (test)
predictions =  predict(rFmodel,test)$predictions[,2]
